{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install pandas dask dask[diagnostics] numpy tomli tqdm pyarrow fastparquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyarrow.parquet as pq\n",
    "import pyarrow as pa\n",
    "from tqdm import trange\n",
    "import dask.dataframe as dd\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tomli\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Config\n",
    "CONFIG_FILE_PATH = \"../config.tomli\"\n",
    "\n",
    "with open(CONFIG_FILE_PATH, 'rb') as config_file:\n",
    "    config = tomli.load(config_file)\n",
    "\n",
    "ETF_DATA_DRIVE_PATH = f\"../{config['data']['etfs']}\"\n",
    "STOCK_DATA_DRIVE_PATH = f\"../{config['data']['stocks']}\"\n",
    "PROCESSED_DATA_DRIVE_PATH = f\"../{config['data']['processed']}\"\n",
    "SYMBOLS_FILE_PATH = f\"../{config['data']['symbols']}\"\n",
    "\n",
    "DATASET_PATH = f\"{PROCESSED_DATA_DRIVE_PATH}/dataset.parquet\"\n",
    "\n",
    "data_dtypes = config['etf_stock_data_type']\n",
    "symbols_dtype = config['symbols_data_types']\n",
    "\n",
    "date_format = config['format']['date_format']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 0 ns\n",
      "Wall time: 0 ns\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Security Name</th>\n",
       "      <th>ETF</th>\n",
       "      <th>CQS Symbol</th>\n",
       "      <th>NASDAQ Symbol</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Symbol</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>A</th>\n",
       "      <td>Agilent Technologies, Inc. Common Stock</td>\n",
       "      <td>N</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AA</th>\n",
       "      <td>Alcoa Corporation Common Stock</td>\n",
       "      <td>N</td>\n",
       "      <td>AA</td>\n",
       "      <td>AA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AAAU</th>\n",
       "      <td>Perth Mint Physical Gold ETF</td>\n",
       "      <td>Y</td>\n",
       "      <td>AAAU</td>\n",
       "      <td>AAAU</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AACG</th>\n",
       "      <td>ATA Creativity Global - American Depositary Sh...</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AACG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AADR</th>\n",
       "      <td>AdvisorShares Dorsey Wright ADR ETF</td>\n",
       "      <td>Y</td>\n",
       "      <td>AADR</td>\n",
       "      <td>AADR</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Security Name ETF CQS Symbol   \n",
       "Symbol                                                                     \n",
       "A                 Agilent Technologies, Inc. Common Stock   N          A  \\\n",
       "AA                        Alcoa Corporation Common Stock    N         AA   \n",
       "AAAU                         Perth Mint Physical Gold ETF   Y       AAAU   \n",
       "AACG    ATA Creativity Global - American Depositary Sh...   N        NaN   \n",
       "AADR                  AdvisorShares Dorsey Wright ADR ETF   Y       AADR   \n",
       "\n",
       "       NASDAQ Symbol  \n",
       "Symbol                \n",
       "A                  A  \n",
       "AA                AA  \n",
       "AAAU            AAAU  \n",
       "AACG            AACG  \n",
       "AADR            AADR  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time\n",
    "# load symbols info and index for future query\n",
    "symbols_df = pd.read_csv(\n",
    "    SYMBOLS_FILE_PATH, \n",
    "    dtype=symbols_dtype, \n",
    "    index_col='Symbol'\n",
    ")\n",
    "# drop other columns to conserve space\n",
    "symbols_df.drop(\n",
    "    [\n",
    "        'Nasdaq Traded', \n",
    "        'Listing Exchange',\n",
    "        'Market Category',\n",
    "        'Round Lot Size',\n",
    "        'Test Issue',\n",
    "        'Financial Status',\n",
    "        # 'CQS Symbol',\n",
    "        # 'NASDAQ Symbol',\n",
    "        'NextShares'\n",
    "    ],\n",
    "    axis=1,\n",
    "    inplace=True\n",
    ")\n",
    "symbols_df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: \n",
    "* This can be stored in a RDBMS which will save the redundant column space ('Symbol', 'Security Name') but going with parquet since it is mentioned in the readme.\n",
    "* Additianl steps can be added to segment the load if RAM utilization is an issue. Since this has not been specified I am working under the assumption that there are no memory constraints.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_file_name(index:int, file_list:list):\n",
    "    return file_list[index]\n",
    "\n",
    "def get_file_path(file_name, base_path:str):\n",
    "    return f\"{base_path}/{file_name}\"\n",
    "\n",
    "def get_symbol(file_name:str):\n",
    "    return file_name.split(\".\")[0]\n",
    "\n",
    "def get_security_name(symbol:str, symbols_df:pd.DataFrame):\n",
    "    try:\n",
    "        security_name = symbols_df.loc[symbol]['Security Name'] \n",
    "        return security_name\n",
    "    except KeyError:\n",
    "        print(f\"unable to extract symbol name for {symbol}\")\n",
    "        return None  \n",
    "\n",
    "def get_security_df(file_path:str, symbol:str, security_name:str)->pd.DataFrame:\n",
    "    # read file\n",
    "    security_df = pd.read_csv(file_path, parse_dates=['Date']) \n",
    "    # parse date format                      \n",
    "    security_df['Date'] = security_df['Date'].dt.strftime(date_format)  \n",
    "    # dropping null or inf values\n",
    "    security_df = security_df.replace([np.inf, -np.inf], np.nan).dropna()   \n",
    "    # set datatypes\n",
    "    security_df['Open'] = security_df['Open'].astype(float)\n",
    "    security_df['High'] = security_df['High'].astype(float)\n",
    "    security_df['Low'] = security_df['Low'].astype(float)\n",
    "    security_df['Close'] = security_df['Close'].astype(float)\n",
    "    security_df['Adj Close'] = security_df['Adj Close'].astype(float)\n",
    "    security_df['Volume'] = security_df['Volume'].round().astype(int)    \n",
    "    # Add additional columns\n",
    "    # note:     \n",
    "    # This can be stored in a RDBMS format (SQL) \n",
    "    # which will save the redundant column space ('Symbol', 'Security Name') \n",
    "    # Since parquet is suggested, it was not considered \n",
    "    security_df['Symbol'] = symbol                                                      \n",
    "    security_df['Security Name'] = security_name    \n",
    "    return security_df                      \n",
    "\n",
    "def get_dataset(base_paths:list, symbols_df:pd.DataFrame):\n",
    "    # init local variables \n",
    "    dataset_dfs = []\n",
    "\n",
    "    # loop over all base paths \n",
    "    for base_path in base_paths:\n",
    "        print(f\"Started extraction for directory {base_path}\")\n",
    "        files = sorted(os.listdir(base_path))\n",
    "        file_count = len(files)\n",
    "        # loop over all securities in the folder\n",
    "        for file_index in trange(file_count, unit=\"file\"):\n",
    "            file_name = get_file_name(\n",
    "                index=file_index,\n",
    "                file_list=files\n",
    "            )\n",
    "            file_path = get_file_path(\n",
    "                file_name=file_name, \n",
    "                base_path=base_path\n",
    "            )\n",
    "            symbol = get_symbol(file_name=file_name)\n",
    "            security_name = get_security_name(\n",
    "                symbol=symbol, \n",
    "                symbols_df=symbols_df\n",
    "            )\n",
    "            # if security info is found continue\n",
    "            if security_name is not None:\n",
    "                security_df = get_security_df(\n",
    "                    file_path=file_path, \n",
    "                    symbol=symbol, \n",
    "                    security_name=security_name\n",
    "                )\n",
    "                dataset_dfs.append(security_df) \n",
    "    \n",
    "    # merge all securities data\n",
    "    dataset_df = pd.concat(dataset_dfs)\n",
    "    del dataset_dfs\n",
    "    return dataset_df\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 0 ns\n",
      "Wall time: 0 ns\n",
      "Started extraction for directory .././data/etfs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2165/2165 [00:38<00:00, 56.97file/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started extraction for directory .././data/stocks\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 140/5884 [00:04<02:14, 42.84file/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unable to extract symbol name for AGM-A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 899/5884 [00:25<01:22, 60.23file/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unable to extract symbol name for CARR#\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|█████▎    | 3114/5884 [01:14<00:53, 51.71file/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unable to extract symbol name for LGF\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|█████████▎| 5494/5884 [02:07<00:09, 43.28file/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unable to extract symbol name for UTX#\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5884/5884 [02:16<00:00, 43.10file/s]\n"
     ]
    }
   ],
   "source": [
    "%time\n",
    "# init data directories\n",
    "base_paths = [ETF_DATA_DRIVE_PATH, STOCK_DATA_DRIVE_PATH]\n",
    "# get dataset\n",
    "dataset_df = get_dataset(\n",
    "    base_paths=base_paths, \n",
    "    symbols_df=symbols_df\n",
    ")\n",
    "# Save dataset to parquet\n",
    "dataset_df.to_parquet(DATASET_PATH, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip freeze > ../requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
